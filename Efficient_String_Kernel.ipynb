{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63db8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from pandas import DataFrame\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddc9d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import random\n",
    "# import seaborn as sns\n",
    "import os.path as path\n",
    "import os\n",
    "# import matplotlib\n",
    "# import matplotlib.font_manager\n",
    "# import matplotlib.pyplot as plt # graphs plotting\n",
    "# import Bio\n",
    "from Bio import SeqIO # some BioPython that will come in handy\n",
    "#matplotlib inline\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# from matplotlib import rc\n",
    "# # for Arial typefont\n",
    "# matplotlib.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from numpy import mean\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "from itertools import product\n",
    "\n",
    "## for Palatino and other serif fonts use:\n",
    "# rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "\n",
    "## for LaTeX typefont\n",
    "# matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "# matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "## for another LaTeX typefont\n",
    "# rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "\n",
    "# rc('text', usetex = True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3676c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.load('E:/RA/Pitari/Dataset/Protein_Subcellular_Localization/Sequences_Protein_Subcellular_Localization_5959.npy',allow_pickle=True)\n",
    "attributes = np.load('E:/RA/Pitari/Dataset/Protein_Subcellular_Localization/Attributes_Protein_Subcellular_Localization_5959.npy',allow_pickle=True)\n",
    "\n",
    "# np.save(\"E:/RA/Pitari/Dataset/Protein_Subcellular_Localization/Sequences_Protein_Subcellular_Localization_5959.npy\",sequences)\n",
    "# np.save(\"E:/RA/Pitari/Dataset/Protein_Subcellular_Localization/Attributes_Protein_Subcellular_Localization_5959.npy\",attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f298f969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5959"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa26eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kmers(sequence, ksize):\n",
    "    # https://homolog.us/blogs/bioinfo/2017/10/25/intro-minimizer/\n",
    "#     seq=\"ATGCGATATCGTAGGCGTCGATGGAGAGCTAGATCGATCGATCTAAATCCCGATCGATTCCGAGCGCGATCAAAGCGCGATAGGCTAGCTAAAGCTAGCA\"\n",
    "#     sequence = seq[:]\n",
    "\n",
    "#     asd = str(sequence)\n",
    "#     asd = np.array2string(sequence)\n",
    "    \n",
    "    string_parsing = []\n",
    "    for ind_test in range(len(sequence)):\n",
    "        string_parsing.append(str(sequence[ind_test]))\n",
    "    \n",
    "    asd = str(string_parsing)\n",
    "    aa_lst_1 = asd.replace(\",\",\"\")\n",
    "    aa_lst_2 = aa_lst_1.replace(\"[\",\"\")\n",
    "    aa_lst_3 = aa_lst_2.replace(\"\\\"\",\"\")\n",
    "    aa_lst_4 = aa_lst_3.replace(\"]\",\"\")\n",
    "    aa_lst_5 = aa_lst_4.replace(\"'\",\"\")\n",
    "    aa_lst_6 = aa_lst_5.replace(\" \",\"\")\n",
    "    aa_lst_6\n",
    "\n",
    "#     print(aa_lst_6)\n",
    "    seq = aa_lst_6[:]\n",
    "    rev=seq[::-1]\n",
    "    \n",
    "    Kmer=ksize\n",
    "#     M=m_size\n",
    "    L=len(seq)\n",
    "\n",
    "    minimizers = []\n",
    "    k_mers_final = []\n",
    "    for i in range(0, L-Kmer+1):\n",
    "\n",
    "            sub_f=seq[i:i+Kmer]\n",
    "            k_mers_final.append(sub_f)\n",
    "            \n",
    "\n",
    "    return k_mers_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ecefe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_size_val = 3\n",
    "# m_size_val = 3\n",
    "\n",
    "protein_kmers_list = []\n",
    "for protein_kmers in range(len(sequences)):\n",
    "#     print(protein_kmers, \"/\",len(sequences))\n",
    "    k_mers_vals = build_kmers(sequences[protein_kmers],k_size_val)\n",
    "\n",
    "    # str(k_mers_vals[0])\n",
    "    k_mers_list = []\n",
    "    for mers_ind in range(len(k_mers_vals)):\n",
    "        k_mers_list.append(str(k_mers_vals[mers_ind]))\n",
    "        \n",
    "    protein_kmers_list.append(k_mers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29e8b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_kmers_final = []\n",
    "for i in range(len(protein_kmers_list)):\n",
    "    tmp = protein_kmers_list[i]\n",
    "    tmp_seq = []\n",
    "    for j in range(len(protein_kmers_list[i])):\n",
    "        aa = tmp[j]\n",
    "        aa_lst = str(list(aa))\n",
    "        aa_lst_1 = aa_lst.replace(\",\",\"\")\n",
    "        aa_lst_2 = aa_lst_1.replace(\"[\",\"\")\n",
    "        aa_lst_3 = aa_lst_2.replace(\"\\\"\",\"\")\n",
    "        aa_lst_4 = aa_lst_3.replace(\"]\",\"\")\n",
    "        aa_lst_5 = aa_lst_4.replace(\"'\",\"\")\n",
    "        aa_lst_6 = aa_lst_5.replace(\" \",\"\")\n",
    "        tmp_seq.append(aa_lst_6)\n",
    "    seq_kmers_final.append(tmp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26956d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_seq_kmers_final_list = [''.join(c) for c in product('ABCDEFGHIJKLMNPQRSTVWXYZ-', repeat=3)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e59e0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_vector = []\n",
    "#cnt_check2 = 0\n",
    "for ii in range(len(seq_kmers_final)):\n",
    "    seq_tmp = seq_kmers_final[ii]\n",
    "    listofzeros = [0] * len(unique_seq_kmers_final_list)\n",
    "    for j in range(len(seq_tmp)):\n",
    "        ind_tmp = unique_seq_kmers_final_list.index(seq_tmp[j])\n",
    "        listofzeros[ind_tmp] = listofzeros[ind_tmp] + 1\n",
    "    frequency_vector.append(listofzeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b43bfb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5959, 15625)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_vector = np.array(frequency_vector)\n",
    "\n",
    "frequency_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85934d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "373604c9",
   "metadata": {},
   "source": [
    "# Kernel Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a68f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new code\n",
    "\n",
    "def compute_gram_matrix(smiles_list1, smiles_list2, sigma=1, reg=1e-10, num_iters=1000):\n",
    "#     X1 = [Chem.MolFromSmiles(smiles) for smiles in smiles_list1]\n",
    "#     X2 = [Chem.MolFromSmiles(smiles) for smiles in smiles_list2]\n",
    "    \n",
    "#     # Check for empty or NoneType molecules\n",
    "#     X1 = [x for x in X1 if x is not None]\n",
    "#     X2 = [x for x in X2 if x is not None]\n",
    "    \n",
    "#     if len(X1) == 0 or len(X2) == 0:\n",
    "#         logging.error(\"One or more input SMILES lists are empty or contain invalid SMILES strings.\")\n",
    "#         return None\n",
    "    \n",
    "#     X1_feats = np.array([Chem.RDKFingerprint(mol) for mol in X1])\n",
    "#     X2_feats = np.array([Chem.RDKFingerprint(mol) for mol in X2])\n",
    "\n",
    "    X1_feats = smiles_list1[:]\n",
    "    X2_feats = smiles_list2[:]\n",
    "    \n",
    "    dist_matrix = pairwise_kernels(X1_feats, X2_feats)\n",
    "\n",
    "\n",
    "    # use Sinkhorn-Knopp algorithm to compute kernel matrix\n",
    "    n = dist_matrix.shape[0]\n",
    "    m = dist_matrix.shape[1]\n",
    "    a = np.ones(n) / n\n",
    "    b = np.ones(m) / m\n",
    "    #K = np.exp(-dist_matrix / sigma)\n",
    "    K = dist_matrix / sigma\n",
    "    K /= K.sum()\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        u = reg * np.log(a)\n",
    "        v = reg * np.log(b)\n",
    "        M = (-sigma * K + u.reshape(-1, 1) + v.reshape(1, -1)) / reg\n",
    "        row_ind, col_ind = linear_sum_assignment(M)\n",
    "        pi = np.zeros((n, m))\n",
    "        pi[row_ind, col_ind] = 1\n",
    "        a_new = pi.sum(axis=1)\n",
    "        b_new = pi.sum(axis=0)\n",
    "        if np.abs(a_new - a).max() < 1e-6 and np.abs(b_new - b).max() < 1e-6:\n",
    "            break\n",
    "        a = a_new\n",
    "        b = b_new\n",
    "\n",
    "    K = np.diag(a).dot(K).dot(np.diag(b))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abeea23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_1 = np.load(\"E:/RA/Drug_Analysis/Dataset/nano-drugbank-master/SMILE_Strings_6897_seq.npy\")\n",
    "\n",
    "# # sm_1 = [\"CCNC(C)C(NC)c1ccccc1\",\"CONC(=O)c1cncnc1\",\"CCNC1CCCN(Cc2ccsc2)C1\"]\n",
    "# sm_2 = sm_1[:]\n",
    "\n",
    "sm_1 = frequency_vector[:]\n",
    "sm_2 = sm_1[:]\n",
    "\n",
    "kernel_matrix = compute_gram_matrix(sm_1,sm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cac9b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_1[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cc2f487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5959, 5959)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1fbce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "# Perform kernel PCA with your customized kernel\n",
    "n_components = 1000\n",
    "kpca = KernelPCA(n_components=n_components, kernel='precomputed')\n",
    "X_kpca = kpca.fit_transform(kernel_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d466f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"E:/RA/Optimized_Kernel_Classification/Dataset/Optimized_Protein_Subcellular_String_Kernel_5959_x_1000.npy\",X_kpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0859f817",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "421d9795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute data preprocessing Done\n"
     ]
    }
   ],
   "source": [
    "X = X_kpca[:]\n",
    "attribute_data = attributes[:]\n",
    "\n",
    "\n",
    "attr_new = []\n",
    "for i in range(len(attribute_data)):\n",
    "    aa = str(attribute_data[i]).replace(\"[\",\"\")\n",
    "    aa_1 = aa.replace(\"]\",\"\")\n",
    "    aa_2 = aa_1.replace(\"\\'\",\"\")\n",
    "    attr_new.append(aa_2)\n",
    "\n",
    "unique_hst = list(np.unique(attr_new))\n",
    "\n",
    "int_hosts = []\n",
    "for ind_unique in range(len(attr_new)):\n",
    "    variant_tmp = attr_new[ind_unique]\n",
    "    ind_tmp = unique_hst.index(variant_tmp)\n",
    "    int_hosts.append(ind_tmp)\n",
    "    \n",
    "print(\"Attribute data preprocessing Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3cb3ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5959, 1000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ae3f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    \n",
    "    \n",
    "    check = pd.DataFrame(roc_auc_dict.items())\n",
    "    return mean(check)\n",
    "\n",
    "def svm_fun_kernel(X_train,y_train,X_test,y_test,kernel_mat):\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "#     clf = svm.SVC()\n",
    "    clf = svm.SVC(kernel=kernel_mat)\n",
    "    \n",
    "    #Train the model using the training sets\n",
    "    clf.fit(kernel_mat, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    #print(\"SVM Kernel Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "    \n",
    "# In[5]\n",
    "##########################  SVM Classifier  ################################\n",
    "def svm_fun(X_train,y_train,X_test,y_test):\n",
    "\n",
    "    #scaler = RobustScaler()\n",
    "    X_train = preprocessing.scale(X_train)  \n",
    "    X_test = preprocessing.scale(X_test)  \n",
    "    \n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    \n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"SVM Accuracy:\",svm_acc)\n",
    "    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Precision:\",svm_prec)\n",
    "    \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM Recall:\",svm_recall)\n",
    "\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"SVM F1 Weighted:\",svm_f1_weighted)\n",
    "    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"SVM F1 macro:\",svm_f1_macro)\n",
    "    \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"SVM F1 micro:\",svm_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    #print(\"SVM Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "#    print(macro_roc_auc_ovo[1])\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "    \n",
    "\n",
    "\n",
    "# In[5]\n",
    "##########################  NB Classifier  ################################\n",
    "def gaus_nb_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "\n",
    "\n",
    "    NB_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Gaussian NB Accuracy:\",NB_acc)\n",
    "\n",
    "    NB_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Precision:\",NB_prec)\n",
    "    \n",
    "    NB_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB Recall:\",NB_recall)\n",
    "    \n",
    "    NB_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Gaussian NB F1 weighted:\",NB_f1_weighted)\n",
    "    \n",
    "    NB_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Gaussian NB F1 macro:\",NB_f1_macro)\n",
    "    \n",
    "    NB_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Gaussian NB F1 micro:\",NB_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix NB : \\n\", confuse)\n",
    "    #print(\"NB Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    check = [NB_acc,NB_prec,NB_recall,NB_f1_weighted,NB_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  MLP Classifier  ################################\n",
    "def mlp_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test_2 = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    # Finally for the MLP- Multilayer Perceptron\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = mlp.predict(X_test_2)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "    \n",
    "    MLP_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"MLP Accuracy:\",MLP_acc)\n",
    "    \n",
    "    MLP_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Precision:\",MLP_prec)\n",
    "    \n",
    "    MLP_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP Recall:\",MLP_recall)\n",
    "    \n",
    "    MLP_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"MLP F1:\",MLP_f1_weighted)\n",
    "    \n",
    "    MLP_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"MLP F1:\",MLP_f1_macro)\n",
    "    \n",
    "    MLP_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"MLP F1:\",MLP_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix MLP : \\n\", confuse)\n",
    "    #print(\"MLP Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [MLP_acc,MLP_prec,MLP_recall,MLP_f1_weighted,MLP_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  knn Classifier  ################################\n",
    "def knn_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "\n",
    "    knn_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Knn Accuracy:\",knn_acc)\n",
    "    \n",
    "    knn_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Precision:\",knn_prec)\n",
    "    \n",
    "    knn_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn Recall:\",knn_recall)\n",
    "    \n",
    "    knn_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Knn F1 weighted:\",knn_f1_weighted)\n",
    "    \n",
    "    knn_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Knn F1 macro:\",knn_f1_macro)\n",
    "    \n",
    "    knn_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Knn F1 micro:\",knn_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix KNN : \\n\", confuse)\n",
    "    #print(\"KNN Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [knn_acc,knn_prec,knn_recall,knn_f1_weighted,knn_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "##########################  Random Forest Classifier  ################################\n",
    "def rf_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    \n",
    "    # Import the model we are using\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestClassifier(n_estimators = 100)\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "\n",
    "    fr_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Random Forest Accuracy:\",fr_acc)\n",
    "    \n",
    "    fr_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Precision:\",fr_prec)\n",
    "    \n",
    "    fr_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest Recall:\",fr_recall)\n",
    "    \n",
    "    fr_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Random Forest F1 weighted:\",fr_f1_weighted)\n",
    "    \n",
    "    fr_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Random Forest F1 macro:\",fr_f1_macro)\n",
    "    \n",
    "    fr_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Random Forest F1 micro:\",fr_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix RF : \\n\", confuse)\n",
    "    #print(\"RF Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [fr_acc,fr_prec,fr_recall,fr_f1_weighted,fr_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "# In[5]\n",
    "    ##########################  Logistic Regression Classifier  ################################\n",
    "def lr_fun(X_train,y_train,X_test,y_test):\n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "\n",
    "    LR_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    LR_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    LR_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    LR_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    LR_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    LR_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix LR : \\n\", confuse)\n",
    "    #print(\"LR Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [LR_acc,LR_prec,LR_recall,LR_f1_weighted,LR_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)\n",
    "\n",
    "\n",
    "def fun_decision_tree(X_train,y_train,X_test,y_test):\n",
    "    from sklearn import tree\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "#     stop = timeit.default_timer()\n",
    "#     print(\"NB Time : \", stop - start) \n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()    \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time_new = stop - start\n",
    "    \n",
    "    dt_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "#     print(\"Logistic Regression Accuracy:\",LR_acc)\n",
    "    \n",
    "    dt_prec = metrics.precision_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Precision:\",LR_prec)\n",
    "    \n",
    "    dt_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression Recall:\",LR_recall)\n",
    "    \n",
    "    dt_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "#     print(\"Logistic Regression F1 weighted:\",LR_f1_weighted)\n",
    "    \n",
    "    dt_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "#     print(\"Logistic Regression F1 macro:\",LR_f1_macro)\n",
    "    \n",
    "    dt_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "#     print(\"Logistic Regression F1 micro:\",LR_f1_micro)\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    #print(\"Confusion Matrix DT : \\n\", confuse)\n",
    "    #print(\"DT Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    ######################## Compute ROC curve and ROC area for each class ################\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [dt_acc,dt_prec,dt_recall,dt_f1_weighted,dt_f1_macro,macro_roc_auc_ovo[1],time_new]\n",
    "    return(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a90cc5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Time :  0.5767147000001387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  6.97230239999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  17.48078929999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  10.112441699999863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  1.9155131999998503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  4.186982299999954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Time :  44.061822199999824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Time :  0.47036560000015015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  6.6314224000000195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  17.7482986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  9.363625799999909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  2.5575770999998895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  7.544029799999862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Time :  68.65280299999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Time :  0.5812312000000475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  6.425783300000148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  16.266424200000074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  8.600007799999958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  1.7162884999997914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  4.075861499999974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Time :  41.80353779999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Time :  0.4422834000001785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  6.949316100000033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  17.90424299999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  10.244895399999905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  1.868494400000145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  4.363292199999933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Time :  49.24806239999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Time :  0.5423679000000448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Time :  5.048068900000089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Time :  16.990991800000074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Time :  8.77225670000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Time :  1.8233192000000145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Time :  3.8146326000000954\n",
      "SVM Time :  43.88160049999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sali85\\Anaconda3\\envs\\New_Env_2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "# X = np.array(seq_data)\n",
    "y = np.array(int_hosts)\n",
    "\n",
    "# print(\"Accuracy   Precision   Recall   F1 (weighted)   F1 (Macro)   F1 (Micro)   ROC AUC\")\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "total_splits = 5\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=total_splits, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "\n",
    "for splits_ind in range(total_splits):\n",
    "    train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"NB Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"MLP Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"KNN Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"RF Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"LR Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"DT Time : \", stop - start) \n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    svm_return = svm_fun(X_train,y_train,X_test,y_test)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"SVM Time : \", stop - start) \n",
    "\n",
    "    gauu_nb_table.append(gauu_nb_return)\n",
    "    mlp_table.append(mlp_return)\n",
    "    knn_table.append(knn_return)\n",
    "    rf_table.append(rf_return)\n",
    "    lr_table.append(lr_return)\n",
    "    dt_table.append(dt_return)\n",
    "    svm_table.append(svm_return)\n",
    "\n",
    "    svm_table_final = DataFrame(svm_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    gauu_nb_table_final = DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    mlp_table_final = DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    knn_table_final = DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    rf_table_final = DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "    lr_table_final = DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n",
    "\n",
    "    dt_table_final = DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                    \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d67f881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #taking average of all k-fold performance values\n",
    "# final_mean_mat = []\n",
    "\n",
    "# final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "# final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "# final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "# final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "# final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "# final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "# final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "# final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "#                                                 \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"], \n",
    "#                           index=[\"SVM\",\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "# final_avg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ad87f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #taking average of all k-fold performance values\n",
    "# final_mean_mat = []\n",
    "\n",
    "# final_mean_mat.append(np.transpose((list(svm_table_final.max()))))\n",
    "# final_mean_mat.append(np.transpose((list(gauu_nb_table_final.max()))))\n",
    "# final_mean_mat.append(np.transpose((list(mlp_table_final.max()))))\n",
    "# final_mean_mat.append(np.transpose((list(knn_table_final.max()))))\n",
    "# final_mean_mat.append(np.transpose((list(rf_table_final.max()))))\n",
    "# final_mean_mat.append(np.transpose((list(lr_table_final.max()))))\n",
    "# final_mean_mat.append(np.transpose((list(dt_table_final.max()))))\n",
    "\n",
    "# final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "#                                                 \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"], \n",
    "#                           index=[\"SVM\",\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "# final_avg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2957020b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 (weighted)</th>\n",
       "      <th>F1 (Macro)</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.013415</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>10.933584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.011163</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.058586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.028568</td>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.029513</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>0.010211</td>\n",
       "      <td>0.791088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.018604</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.663096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.036528</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.749510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.007413</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.012434</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.012434</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>0.011397</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>1.534639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall  F1 (weighted)  F1 (Macro)   ROC AUC  \\\n",
       "SVM  0.004739   0.006544  0.004739       0.004600    0.013415  0.006078   \n",
       "NB   0.006369   0.015412  0.006369       0.004592    0.011163  0.005167   \n",
       "MLP  0.029686   0.028568  0.029686       0.029513    0.018562  0.010211   \n",
       "KNN  0.004045   0.018604  0.004045       0.006785    0.007203  0.003118   \n",
       "RF   0.019855   0.036528  0.019855       0.018951    0.010128  0.005943   \n",
       "LR   0.010719   0.005069  0.010719       0.007413    0.001275  0.000000   \n",
       "DT   0.012434   0.008664  0.012434       0.009590    0.011397  0.006378   \n",
       "\n",
       "       Runtime  \n",
       "SVM  10.933584  \n",
       "NB    0.058586  \n",
       "MLP   0.791088  \n",
       "KNN   0.663096  \n",
       "RF    0.749510  \n",
       "LR    0.310034  \n",
       "DT    1.534639  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "final_mean_mat.append(np.transpose((list(svm_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.std()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.std()))))\n",
    "\n",
    "final_avg_mat = DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"ROC AUC\",\"Runtime\"], \n",
    "                          index=[\"SVM\",\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef672ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
